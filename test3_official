#import urllib.request
from selenium import webdriver
from selenium.webdriver.common.keys import Keys
import time
from bs4 import BeautifulSoup
import re
import csv

month_names = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December']	#Note, May is short enoug to not need abbreviation, so make sure we have full week name like Thursday instead of Thur for full date stamp. THIS stuff: "(Thu, May 30)" is ignored by reader
day_names = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']


def initiate_driver() : 
	"""Creates an instance of FireFox web driver."""

	driver = webdriver.Firefox()
	return driver


def convert_to_month_num(str_month_name):
	"""Given the full name of the month as a string, returns an integer value representation of the month.

	For example: January would return 1. Note the input of "Jan" would fail here.
	"""

	month_names = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December']
	return (month_names.index(str_month_name) + 1)


def convert_to_yyyymmdd_date(str_year, str_month, str_day):
	""" Given the year, month, and day as strings, return the yyyymmdd format as a string.

	For example: convert_to_yyyymmdd_date("2013", "1", "5") returns "20130105."
	"""

	if len(str_month) == 1:
		str_month = "0" + str_month
	if len(str_day) == 1:
		str_day = "0" + str_day
	return str(str_year + str_month + str_day)


def find_open_ct (info) :
	"""Looks through a list generated by bs4's (BeautifulSoup4 python library) via the findall() function.
	Returns the index of the first item within the list that contains a "span" tag with a full month name ("January" not "Jan") within the item's text.

	For example: 
	info = soup.find_all('span')
	#now info is a list containing

	#[<span id="yfs_ad_"> jumble of words</span>
	#<span id="yfs_ad_"> Jan</span>
	#<span id="yfs_ad_"> January</span>]

    num = find_open_ct (info) # num is 2. Note "Jan" is an abbreviated month name. Also note, there is no abbreviation for the month of May.
	"""

	month_names = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December']
	startCt = 0
	for line in info:
		startCt = startCt + 1
		if line.name == "span":
			for m in month_names:
				if m in line.text: 
					return startCt -1

def find_end_ct (info, name = "span", end_ct_identifiers = None) :
	"""Looks through a list generated by bs4's (BeautifulSoup4 python library) via the findall() function.
	Returns the index of the first item within the list that contains a "span" tag with a full month name ("January" not "Jan") within the item's text.

	For example: 
	info = soup.find_all('span')
	#now info is a list containing

	#[<span id="yfs_ad_"> jumble of words</span>
	#<span id="yfs_ad_"> Jan</span>
	#<span id="yfs_ad_"> January</span>]

    num = find_open_ct (info) # num is 2. Note "Jan" is an abbreviated month name. Also note, there is no abbreviation for the month of May.

    #function follows this convention: def opt_fun(x1, x2, *positional_parameters, **keyword_parameters):
	"""

	#The default value is evaluated only once. Used as guard. See http://docs.python.org/3.3/tutorial/controlflow.htmlhttp://docs.python.org/3.3/tutorial/controlflow.html
	if end_ct_identifiers == None:
		#default ending for YahooFinance Scraper looks like this: b'<span>AdChoices</span>' or like this:...
		# '<span id="yfs_params_vcr" style="display:none">{"yrb_token" : "YFT_MARKET_CLOSED", "tt" : "1380231285", "s" : "qcor", "k" : "a'
		end_ct_identifiers = ['AdChoices', 'yrb_token']

	end_ct = 0
	for line in info:
		end_ct = end_ct + 1
		if line.name == name:
			for identifier in end_ct_identifiers:
				if identifier in line.text:
					return end_ct - 1

		#if -1 not there results in extra line crripts data "b'<span id="yfs_params_vcr" style="display:none">{"yrb_token" : "YFT_MARKET_CLOSED", "tt" : "1384590083", "s" : "aa", "k" : "a00,a50,b00,b60,c10,c63,c64,c85,c86,g00,g53,h00,h53,l10,l84,l85,l86,p20,p43,p44,t10,t53,t54,v00,v53", "o" : "^dji,^ixic", "j" : "c10,l10,p20,t10", "version" : "1.0", "market" : {"NAME" : "U.S.", "ID" : "us_market", "TZ" : "EST", "TZOFFSET" : "-18000", "open" : "", "close" : "", "flags" : {}} , "market_status_yrb" : "YFT_MARKET_CLOSED" , "portfolio" : { "fd" : { "txns" : [ ]},"dd" : "","pc" : "","pcs" : ""}, "STREAMER_SERVER" : "http://streamerapi.finance.yahoo.com", "DOC_DOMAIN" : "finance.yahoo.com", "localize" : "0" , "throttleInterval" : "1000" , "arrowAsChangeSign" : "true" , "up_arrow_icon" : "http://l.yimg.com/a/i/us/fi/03rd/up_g.gif" , "down_arrow_icon" : "http://l.yimg.com/a/i/us/fi/03rd/down_r.gif" , "up_color" : "green" , "down_color" : "red" , "pass_market_id" : "0" , "mu" : "1" , "lang" : "en-US" , "region" : "US" }</span>'"

def parse_yahoo_headlines_date(str):
	"""Given a date string from YahooFinance's Headlines, returns a list containing name of the full name of the day, month, date number, and year.

	For example: parse_yahoo_headlines_date("Tuesday, November 12, 2013") returns ["Tuesday", "November", "12", "2013"].
	"""
	list = []
	for i in range(len(str)):
		if ',' == str[i]:
			list.append(i)
	comma1 = list[0]
	comma2 = list[1] #WHAT IF THE HEADLINE IS TWO LINES LONG?!?!?!?!?!?! HERE IS TEH PROBLEM, INITIATLED LINE 120. SEE FIRE FOX WINDOW
	day_name = str[:comma1]	
	name_and_month = str[comma1+2:comma2]
	space_loc = name_and_month.find(' ')
	month = name_and_month[:space_loc]
	day_num = name_and_month[space_loc+1:]
	year = str[comma2+2:]

	return ([day_name,month,day_num,year])					

def enter_ticker(ticker):
	"""Given a stock ticker as a string, uses the web driver to input the ticker's name into YahooFinance's search box.
	"""

	driver = initiate_driver()
	driver.get("http://finance.yahoo.com/")
	elem = driver.find_element_by_id("txtQuotes")
	elem.send_keys(ticker)
	elem.send_keys(Keys.RETURN)
	time.sleep(1.5)
	return driver

def navigate_to_headlines(driver):
	"""Uses the web driver to navigate to the "headlines" tab of YahooFinance's website.
	"""

	driver.find_element_by_partial_link_text("Headlines").click()
	time.sleep(1.5)
	return driver

def click_get_older_news(driver):
	"""Uses the web driver to navigate and click on the "Older Headlines" tab of YahooFinance's website.
	"""	
	temp_soup=BeautifulSoup(driver.page_source)
	info = temp_soup.find_all('a')
	for item in info:
		if "Older Headlines" in item.text:
			link = "http://finance.yahoo.com" + item.get('href')
			break
	#driver.get(link)
	driver.get(link)
	time.sleep(2.0)
	soup=BeautifulSoup(driver.page_source)
	return {'soup':soup, 'driver': driver} #dictionary result['y0']  http://stackoverflow.com/questions/354883/how-do-you-return-multiple-values-in-python


def create_text_file_name(ticker):
	"""Creates a name for the text file we are going to write the headlines towards.

	Requires a stock ticker as a string input. For example:
	fid = create_text_file_name('AAPL')
	#fid will be 'YahooHeadlines_AAPL.csv'
	"""

	file_name = 'YahooHeadlines_' + ticker + '.csv'
	return file_name

def scrape_yahoofinance_headlines(ticker):
	"""Given a ticker name, will go to YahooFinance's website and download all the headlines for that particular stock, and write the output file to default directory as a csv file.
	"""

	driver = enter_ticker(ticker)
	file_name = create_text_file_name(ticker)
	driver = navigate_to_headlines(driver)

	#for first iteration
	soup=BeautifulSoup(driver.page_source)

	while True: #ensures we don;t hit a "No headlines available for QCOR prior to May 14, 2012." Event. If this does happen, startCt and endCt are None
		#soup=BeautifulSoup(driver.page_source)
		val = 0
		start_ct = 0
		end_ct = 0

		with open(file_name, 'a', newline='') as csvfile:
			#writer = csv.writer(csvfile, delimiter=',', quotechar='"', quoting=csv.QUOTE_NONE)
			writer = csv.writer(csvfile, delimiter=',')

			info = soup.find_all(['span', 'li'])
			start_ct = find_open_ct(info)
			end_ct = find_end_ct (info)

			if ( (start_ct == None) or (end_ct == None)): #BREAK statement to end search
				print("------------END----------------")
				driver.close()
				break
					
			curr_date_stamp = ''
			headline = ''
			link = ''
			new_citation = ''

			for item in info[start_ct:end_ct]:
				print('line 115--->', item.encode('ascii')) #<+_+_+_+_+_+_+_+_+_+_

				#Check if full month name and full weekday/weekend name is in string, otherwise we could grab "(Thu, May 30)" by accident
				if item.name == "span":
					for m in month_names:
						if (m in item.text):
							for d in day_names:
								if (d in item.text):
									curr_date_stamp = item.text
									curr_date_stamp_array = parse_yahoo_headlines_date(curr_date_stamp) #<----------------------------
									curr_date_stamp = item.text.encode('ascii')
									#print('----->',currDateStamp)

							#print(currDateStamp)
				if item.name == "li":
					#for citation
					citation = item.find('cite').text
					parens = citation.find('(')
					new_citation = citation[0:parens-1] #extra one space back to remove encoding error

					#removing 'at' from 'at Wall St. Cheat Sheet' if 'at' is present
					if 'at ' in new_citation:
						new_citation = new_citation[3:]
		
					#encode newCitation after manipulation in teh if statement
					new_citation = new_citation.encode('ascii') #<------------
		

					#get headline name
					headline = item.find('a').text.encode('ascii',errors='ignore') #<-----------
					#headline = item.find('a').text.encode('utf',errors='ignore') #<-----------
		
					#get link
					link = item.find('a').get('href').encode('ascii') #<------
		

				if curr_date_stamp and headline and link and new_citation and curr_date_stamp_array:
					yyyymmdd_date = convert_to_yyyymmdd_date((curr_date_stamp_array[3]), str(convert_to_month_num(curr_date_stamp_array[1])), str(curr_date_stamp_array[2])) 
					newsLine = [yyyymmdd_date, curr_date_stamp_array[0], curr_date_stamp_array[1], curr_date_stamp_array[2], curr_date_stamp_array[3], ticker, headline.decode("ascii"), new_citation.decode("ascii"), link.decode("ascii")]			
					writer.writerow( newsLine )#<-----------------------------------------------------------------------------------------------------------------------------
					#print(newsLine)
					link = ''
					new_citation = ''
					yyyymmdd_date = ''

		driver_dict = click_get_older_news(driver)	
		soup = driver_dict['soup']
		driver = driver_dict['driver']
		driver_dict = ''
# --------------------------------------------------stuff to run always here such as class/def------------------------------------------------------------------------

#If you have source control over this file, you could write it with the
#more standard idiom.Use the if __name__ == '__main__' idiom -- __name__ is a special variable whose value is '__main__' if the module is being run as a script, and the module name if it's imported.

def main():
	ticker_list = ["CSCO", "JNPR", "HPQ"]
	for stck in ticker_list:
		scrape_yahoofinance_headlines(stck)

if __name__ == "__main__":
	# stuff only to run when not called via 'import' here
	main()

